{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D,BatchNormalization,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from numpy import unique\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "df=pd.read_csv(r'C:\\Users\\pc\\Soil_Ferrtlity.csv', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PH</th>\n",
       "      <th>OC</th>\n",
       "      <th>Mg</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>Zn</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Mn</th>\n",
       "      <th>Sand</th>\n",
       "      <th>Silt</th>\n",
       "      <th>Clay</th>\n",
       "      <th>CaCO3</th>\n",
       "      <th>CEC</th>\n",
       "      <th>Fertility_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.90</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1.01</td>\n",
       "      <td>380</td>\n",
       "      <td>60.00</td>\n",
       "      <td>279</td>\n",
       "      <td>0.48</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.64</td>\n",
       "      <td>5.70</td>\n",
       "      <td>65.30</td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.90</td>\n",
       "      <td>3.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.23</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.43</td>\n",
       "      <td>350</td>\n",
       "      <td>55.70</td>\n",
       "      <td>330</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.46</td>\n",
       "      <td>5.60</td>\n",
       "      <td>94.40</td>\n",
       "      <td>9.90</td>\n",
       "      <td>13.70</td>\n",
       "      <td>4.61</td>\n",
       "      <td>10.19</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.56</td>\n",
       "      <td>5.02</td>\n",
       "      <td>1.03</td>\n",
       "      <td>364</td>\n",
       "      <td>55.60</td>\n",
       "      <td>265</td>\n",
       "      <td>0.46</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.10</td>\n",
       "      <td>84.50</td>\n",
       "      <td>6.90</td>\n",
       "      <td>12.60</td>\n",
       "      <td>3.53</td>\n",
       "      <td>12.32</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.32</td>\n",
       "      <td>6.04</td>\n",
       "      <td>1.06</td>\n",
       "      <td>312</td>\n",
       "      <td>48.00</td>\n",
       "      <td>233</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.80</td>\n",
       "      <td>70.50</td>\n",
       "      <td>5.70</td>\n",
       "      <td>13.80</td>\n",
       "      <td>5.21</td>\n",
       "      <td>7.02</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.50</td>\n",
       "      <td>5.08</td>\n",
       "      <td>3.13</td>\n",
       "      <td>342</td>\n",
       "      <td>41.00</td>\n",
       "      <td>312</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.60</td>\n",
       "      <td>87.50</td>\n",
       "      <td>6.70</td>\n",
       "      <td>5.80</td>\n",
       "      <td>4.80</td>\n",
       "      <td>10.76</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504</th>\n",
       "      <td>5.63</td>\n",
       "      <td>2.04</td>\n",
       "      <td>4.04</td>\n",
       "      <td>197</td>\n",
       "      <td>10.72</td>\n",
       "      <td>112</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>6.52</td>\n",
       "      <td>90.81</td>\n",
       "      <td>10.72</td>\n",
       "      <td>8.67</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.87</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12505</th>\n",
       "      <td>7.29</td>\n",
       "      <td>0.56</td>\n",
       "      <td>4.41</td>\n",
       "      <td>213</td>\n",
       "      <td>26.62</td>\n",
       "      <td>259</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.94</td>\n",
       "      <td>86.38</td>\n",
       "      <td>5.39</td>\n",
       "      <td>7.42</td>\n",
       "      <td>2.83</td>\n",
       "      <td>12.26</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12506</th>\n",
       "      <td>6.34</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1.24</td>\n",
       "      <td>103</td>\n",
       "      <td>27.80</td>\n",
       "      <td>106</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.90</td>\n",
       "      <td>78.85</td>\n",
       "      <td>3.51</td>\n",
       "      <td>8.39</td>\n",
       "      <td>11.43</td>\n",
       "      <td>15.83</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12507</th>\n",
       "      <td>5.46</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.81</td>\n",
       "      <td>206</td>\n",
       "      <td>15.86</td>\n",
       "      <td>222</td>\n",
       "      <td>1.53</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.34</td>\n",
       "      <td>82.83</td>\n",
       "      <td>5.89</td>\n",
       "      <td>9.22</td>\n",
       "      <td>15.43</td>\n",
       "      <td>14.32</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12508</th>\n",
       "      <td>5.32</td>\n",
       "      <td>2.61</td>\n",
       "      <td>3.74</td>\n",
       "      <td>154</td>\n",
       "      <td>10.11</td>\n",
       "      <td>181</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5.47</td>\n",
       "      <td>95.32</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.32</td>\n",
       "      <td>4.21</td>\n",
       "      <td>11.76</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12509 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PH     OC    Mg    N      P    K    Zn    Fe    Cu    Mn   Sand  \\\n",
       "0      5.90  11.50  1.01  380  60.00  279  0.48  6.40  0.64  5.70  65.30   \n",
       "1      6.23   6.02  1.43  350  55.70  330  0.27  6.40  0.46  5.60  94.40   \n",
       "2      5.56   5.02  1.03  364  55.60  265  0.46  6.20  0.56  6.10  84.50   \n",
       "3      6.32   6.04  1.06  312  48.00  233  2.75  5.90  0.82  1.80  70.50   \n",
       "4      6.50   5.08  3.13  342  41.00  312  0.34  8.30  0.64  8.60  87.50   \n",
       "...     ...    ...   ...  ...    ...  ...   ...   ...   ...   ...    ...   \n",
       "12504  5.63   2.04  4.04  197  10.72  112  0.88  3.54  0.55  6.52  90.81   \n",
       "12505  7.29   0.56  4.41  213  26.62  259  0.08  4.41  0.63  1.94  86.38   \n",
       "12506  6.34   2.69  1.24  103  27.80  106  1.03  3.68  0.47  2.90  78.85   \n",
       "12507  5.46   1.27  1.81  206  15.86  222  1.53  5.52  0.22  2.34  82.83   \n",
       "12508  5.32   2.61  3.74  154  10.11  181  0.73  3.28  0.49  5.47  95.32   \n",
       "\n",
       "        Silt   Clay  CaCO3    CEC Fertility_Class  \n",
       "0       6.80   8.90   3.72   2.81       Very High  \n",
       "1       9.90  13.70   4.61  10.19       Very High  \n",
       "2       6.90  12.60   3.53  12.32       Very High  \n",
       "3       5.70  13.80   5.21   7.02       Very High  \n",
       "4       6.70   5.80   4.80  10.76       Very High  \n",
       "...      ...    ...    ...    ...             ...  \n",
       "12504  10.72   8.67   9.14   9.87        Moderate  \n",
       "12505   5.39   7.42   2.83  12.26        Moderate  \n",
       "12506   3.51   8.39  11.43  15.83        Moderate  \n",
       "12507   5.89   9.22  15.43  14.32        Moderate  \n",
       "12508   4.14   5.32   4.21  11.76        Moderate  \n",
       "\n",
       "[12509 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 4, 0, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df['Fertility_Class'] = le.fit_transform(df['Fertility_Class'])\n",
    "df['Fertility_Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.9  11.5   1.01 ...  8.9   3.72  2.81]\n",
      " [ 6.23  6.02  1.43 ... 13.7   4.61 10.19]\n",
      " [ 5.56  5.02  1.03 ... 12.6   3.53 12.32]\n",
      " ...\n",
      " [ 6.34  2.69  1.24 ...  8.39 11.43 15.83]\n",
      " [ 5.46  1.27  1.81 ...  9.22 15.43 14.32]\n",
      " [ 5.32  2.61  3.74 ...  5.32  4.21 11.76]]\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "Y = df.iloc[:, -1].values\n",
    "Y= le.fit_transform(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12509, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3        1.         0.1039261  ... 0.41789216 0.14066631 0.05994898]\n",
      " [0.41       0.51718062 0.15242494 ... 0.7120098  0.18773136 0.37372449]\n",
      " [0.18666667 0.42907489 0.10623557 ... 0.64460784 0.13061872 0.46428571]\n",
      " ...\n",
      " [0.44666667 0.22378855 0.13048499 ... 0.38664216 0.5483871  0.61352041]\n",
      " [0.15333333 0.09867841 0.19630485 ... 0.4375     0.75991539 0.54931973]\n",
      " [0.10666667 0.21674009 0.41916859 ... 0.19852941 0.16657853 0.44047619]]\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# fit and transform in one step\n",
    "normalized = scaler.fit_transform(X)\n",
    "# inverse transform''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "inverse = scaler.inverse_transform(normalized)\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest=train_test_split(X, Y, test_size=0.2, random_state=42, shuffle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_14 (Conv1D)          (None, 13, 64)            256       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 13, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 11, 64)            12352     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 11, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 5, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 320)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                20544     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,733\n",
      "Trainable params: 33,605\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(15,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "157/157 [==============================] - 3s 13ms/step - loss: 0.8009 - accuracy: 0.6694 - val_loss: 0.8988 - val_accuracy: 0.5116\n",
      "Epoch 2/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.6222 - accuracy: 0.7481 - val_loss: 0.5808 - val_accuracy: 0.7950\n",
      "Epoch 3/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.5793 - accuracy: 0.7628 - val_loss: 0.5370 - val_accuracy: 0.7918\n",
      "Epoch 4/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.5615 - accuracy: 0.7732 - val_loss: 0.5567 - val_accuracy: 0.8054\n",
      "Epoch 5/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.5536 - accuracy: 0.7770 - val_loss: 0.5120 - val_accuracy: 0.8046\n",
      "Epoch 6/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.5075 - accuracy: 0.7934 - val_loss: 0.4670 - val_accuracy: 0.8437\n",
      "Epoch 7/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4693 - accuracy: 0.8160 - val_loss: 0.4393 - val_accuracy: 0.8149\n",
      "Epoch 8/30\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.4420 - accuracy: 0.8244 - val_loss: 0.5323 - val_accuracy: 0.7706\n",
      "Epoch 9/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4504 - accuracy: 0.8154 - val_loss: 0.4024 - val_accuracy: 0.8581\n",
      "Epoch 10/30\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.4023 - accuracy: 0.8427 - val_loss: 0.4119 - val_accuracy: 0.8237\n",
      "Epoch 11/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4126 - accuracy: 0.8306 - val_loss: 0.3388 - val_accuracy: 0.8645\n",
      "Epoch 12/30\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3796 - accuracy: 0.8513 - val_loss: 0.3078 - val_accuracy: 0.8985\n",
      "Epoch 13/30\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.3848 - accuracy: 0.8481 - val_loss: 0.3274 - val_accuracy: 0.8905\n",
      "Epoch 14/30\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.3716 - accuracy: 0.8541 - val_loss: 0.2838 - val_accuracy: 0.9089\n",
      "Epoch 15/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.3678 - accuracy: 0.8545 - val_loss: 0.3178 - val_accuracy: 0.8945\n",
      "Epoch 16/30\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3463 - accuracy: 0.8616 - val_loss: 0.2937 - val_accuracy: 0.9001\n",
      "Epoch 17/30\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.3396 - accuracy: 0.8643 - val_loss: 0.3011 - val_accuracy: 0.8813\n",
      "Epoch 18/30\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.3199 - accuracy: 0.8738 - val_loss: 0.2813 - val_accuracy: 0.8949\n",
      "Epoch 19/30\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.3349 - accuracy: 0.8662 - val_loss: 0.2402 - val_accuracy: 0.9185\n",
      "Epoch 20/30\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.3162 - accuracy: 0.8718 - val_loss: 0.2404 - val_accuracy: 0.9205\n",
      "Epoch 21/30\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.2877 - accuracy: 0.8899 - val_loss: 0.2254 - val_accuracy: 0.9197\n",
      "Epoch 22/30\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.2743 - accuracy: 0.8935 - val_loss: 0.1997 - val_accuracy: 0.9337\n",
      "Epoch 23/30\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.2899 - accuracy: 0.8839 - val_loss: 0.2081 - val_accuracy: 0.9321\n",
      "Epoch 24/30\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2826 - accuracy: 0.8856 - val_loss: 0.3715 - val_accuracy: 0.8449\n",
      "Epoch 25/30\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.2545 - accuracy: 0.8986 - val_loss: 0.2033 - val_accuracy: 0.9281\n",
      "Epoch 26/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.2870 - accuracy: 0.8856 - val_loss: 0.1894 - val_accuracy: 0.9365\n",
      "Epoch 27/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.2644 - accuracy: 0.8934 - val_loss: 0.1771 - val_accuracy: 0.9428\n",
      "Epoch 28/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.2439 - accuracy: 0.9016 - val_loss: 0.1784 - val_accuracy: 0.9476\n",
      "Epoch 29/30\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.2275 - accuracy: 0.9100 - val_loss: 0.1574 - val_accuracy: 0.9504\n",
      "Epoch 30/30\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.2362 - accuracy: 0.9070 - val_loss: 0.1629 - val_accuracy: 0.9504\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(xtrain, ytrain, validation_data=(xtest, ytest), batch_size=64,epochs=30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.9490\n",
      "Loss: 0.1612800806760788  Accuracy: 0.9490357041358948\n"
     ]
    }
   ],
   "source": [
    "acc = model.evaluate(xtrain, ytrain)\n",
    "print(\"Loss:\", acc[0], \" Accuracy:\", acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(15,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    history= model.fit(X[train], Y[train], epochs=30, batch_size=64, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
